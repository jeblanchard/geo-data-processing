{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module that makes downloading and using many GSE datasets fast and easy.\\n\\nAuthor: Joshua Blanchard, last update: 4/28/2021\\n\\nA typical workflow:\\n\\n    Download wanted GSE family files using the download() function.\\n\\n    Extract content from these files using the extract() function.\\n\\n    Use the family_dict() function to convert data to pandas.DataFrame objects.\\n\\n    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"A module that makes downloading and using many GSE datasets fast and easy.\n",
    "\n",
    "Author: Joshua Blanchard, last update: 4/28/2021\n",
    "\n",
    "A typical workflow:\n",
    "\n",
    "    Download wanted GSE family files using the download() function.\n",
    "\n",
    "    Extract content from these files using the extract() function.\n",
    "\n",
    "    Use the family_dict() function to convert data to pandas.DataFrame objects.\n",
    "\n",
    "    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re as re\n",
    "import xmltodict\n",
    "import shutil\n",
    "import ftplib\n",
    "import tarfile\n",
    "import pickle\n",
    "# import requests\n",
    "# import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__base_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "__hidden_path = \".aidp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a family ID, will output a dictionary. Keys will be the sample IDs, values will be the corresponding\n",
    "    pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "\n",
    "#     let's check if we already have this dictionary saved\n",
    "    if not os.path.exists(\"./\" + __hidden_path):\n",
    "        os.mkdir(__hidden_path)\n",
    "    \n",
    "    dict_path = __hidden_path + \"/\" + GSE_family + \"_dict\"    \n",
    "    if not os.path.exists(dict_path):\n",
    "    \n",
    "        family_directory = __family_path(GSE_family)\n",
    "        total_list = os.listdir(family_directory)\n",
    "        valid_files = []\n",
    "\n",
    "        for file_name in total_list:\n",
    "            match = re.match(r\"GSM\", file_name)\n",
    "            if match:\n",
    "                valid_files.append(file_name)\n",
    "\n",
    "        family_dict = {}\n",
    "        for file_name in valid_files:\n",
    "            file_df = __load_file(os.path.join(family_directory, file_name))\n",
    "            sample_id = re.match(r\"GSM\\d+\", file_name).group(0)\n",
    "            family_dict[sample_id] = file_df\n",
    "            \n",
    "        dict_file = open(dict_path, 'wb')\n",
    "        pickle.dump(family_dict, dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "    else:\n",
    "        dict_file = open(dict_path, 'rb')\n",
    "        family_dict = pickle.load(dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "        \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __family_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build paths to the family's directory.\n",
    "    \n",
    "    I downloaded the files using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "        \n",
    "    return os.path.join(__base_path, GSE_family + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_file(file_directory):\n",
    "#     clean data file\n",
    "#     convert to a dataframe object and return\n",
    "\n",
    "    \"\"\"\n",
    "    Given a file name will output a corresponding pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        clean_dict = __clean(file_directory)\n",
    "    except PermissionError:\n",
    "        print(\"You likely inputted the path of a directory, not a file.\")\n",
    "    \n",
    "#     return pd.DataFrame({\"site\": clean_dict[\"col_1\"], \"measurement\": clean_dict[\"col_2\"]})\n",
    "    return pd.DataFrame(data= clean_dict[\"col_2\"], index= clean_dict[\"col_1\"], columns= [\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean(file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans a given .txt file.\n",
    "    \n",
    "    Returns a dictionary:\n",
    "    \n",
    "    \"site\": first column\n",
    "    \"measurement\": second column\n",
    "    \"bad_rows\": list of all the invalid rows\n",
    "    \"\"\"\n",
    "\n",
    "    valid_rows = []\n",
    "    not_valid_rows = []\n",
    "    file = open(file_path, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "#         checks for only the first two columns\n",
    "        line_match = re.match(r\"\\S+\\t\\S+\", line)\n",
    "        if line_match:\n",
    "            valid_rows.append(line_match.group(0))\n",
    "        else:\n",
    "            not_valid_rows.append(line)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "#     now let's split our valid_rows list into two lists, one for each column\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    for row in valid_rows:\n",
    "        row_match = re.match(r\"(\\S+)\\t(\\S+)\", row)\n",
    "        col_1.append(row_match.group(1))\n",
    "        col_2.append(row_match.group(2))\n",
    "        \n",
    "    return {\"col_1\":col_1, \"col_2\":col_2, \"bad_rows\":not_valid_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(GSE_family, sample_id, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": The unit of the outputted age is the same as how it is documented by the study (typically in years).\n",
    "    \"\"\"\n",
    "    \n",
    "    xml_path = __xml_path(GSE_family)\n",
    "    \n",
    "    try:\n",
    "        family_dict = __xml_to_dict(xml_path)\n",
    "    except:\n",
    "        raise RuntimeError(\"It seems the files for the GSE family you inputted have not been extracted.\")\n",
    "    \n",
    "    \n",
    "    family_dict_index = __dict_index(GSE_family, sample_id)\n",
    "    section_len = len(family_dict[\"MINiML\"][\"Sample\"][family_dict_index][\"Channel\"][\"Characteristics\"])\n",
    "\n",
    "    if info == \"age\":\n",
    "        \n",
    "        for i in np.arange(section_len):\n",
    "            tag = family_dict[\"MINiML\"][\"Sample\"][family_dict_index][\"Channel\"][\"Characteristics\"][i][\"@tag\"]\n",
    "            match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\n",
    "            if match:\n",
    "                index = i\n",
    "\n",
    "#         return int(family_dict[\"MINiML\"][\"Sample\"][family_dict_index][\"Channel\"][\"Characteristics\"][index][\"#text\"])\n",
    "        age_str = family_dict[\"MINiML\"][\"Sample\"][family_dict_index][\"Channel\"][\"Characteristics\"][index][\"#text\"]\n",
    "        int_match = re.search(r\"\\d+\", age_str)\n",
    "        return int_match.group(0)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        raise RuntimeError(\"You likely gave an invalid string for the info parameter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build a path to the family's .xml.\n",
    "    \n",
    "    I downloaded these families using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return os.path.join(__base_path, GSE_family + \"/\" + GSE_family + \"_family.xml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_to_dict(xml_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to convert a .xml file at xml_path to a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_file = open(xml_path,'r+b')\n",
    "    family_dict = xmltodict.parse(family_file)\n",
    "    family_file.close()\n",
    "    \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __dict_index(GSE_family, sample_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gives the index of where in the dictionary the sample's information is.\n",
    "    \"\"\"\n",
    "    \n",
    "    return __sample_indices(GSE_family)[sample_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sample_indices(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to return the indices of each sample's information within the associated family dictionary. Returns a dictionary\n",
    "    with keys equal to the sample ID (\"GSM***\") and values equal to the index of that sample's information within the family\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_dir = __family_path(GSE_family)\n",
    "    file_list = os.listdir(family_dir)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for file_name in file_list:\n",
    "        sample_match = re.match(r\"GSM\", file_name)\n",
    "        if sample_match:\n",
    "            filtered_list.append(file_name)\n",
    "            \n",
    "    for i in np.arange(len(filtered_list)):\n",
    "        filtered_list[i] = re.match(r\"GSM\\d+\", filtered_list[i]).group(0)\n",
    "        \n",
    "    index_dict = {}\n",
    "    index = 0\n",
    "\n",
    "    for sample_id in filtered_list:\n",
    "        index_dict[sample_id] = index\n",
    "        index += 1\n",
    "        \n",
    "    return index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/\" + \"GSE41037\" + \"/miniml/\" + \"GSE41027\" + \"_family.xml.tgz\"\n",
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSE1/miniml/GSE1_family.xml.tgz\"\n",
    "\n",
    "def download(GSE_family_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Will download family .tgz files to the following directory: \"./data/\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(GSE_family_list) == str):\n",
    "        GSE_family_list = [GSE_family_list]\n",
    "\n",
    "    url = \"ftp.ncbi.nlm.nih.gov\"\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login()\n",
    "    \n",
    "    if not os.path.exists(__base_path):\n",
    "        os.mkdir(__base_path)\n",
    "    \n",
    "    for GSE_family in GSE_family_list:\n",
    "        \n",
    "        ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/miniml/\")\n",
    "        filename = GSE_family + \"_family.xml.tgz\"\n",
    "        \n",
    "        if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family)):\n",
    "            local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "            ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "            local_file.close()\n",
    "\n",
    "    ftp.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sub_directory(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE ID will return the corresponding sub-directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    gse_int = __ID_to_int(GSE_ID)\n",
    "    \n",
    "    if gse_int <= 171:\n",
    "        ret_str = \"GSE\" + str(gse_int) + \"nnn\"\n",
    "    else:\n",
    "        first_3_dig = int(str(gse_int)[0:3])\n",
    "        if first_3_dig <= 171:\n",
    "            ret_str = \"GSE\" + str(first_3_dig) + \"nnn\"\n",
    "        else:\n",
    "            first_2_dig_str = str(gse_int)[0:2]\n",
    "            ret_str = \"GSE\" + first_2_dig_str + \"nnn\"\n",
    "            \n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ID_to_int(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given some GSE ID will return the corresponding integer as an int.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    __ID_to_int(\"GSE41037\") will return 41037.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r\"\\d+\", GSE_ID)\n",
    "    \n",
    "    if not match:\n",
    "        print(GSE_ID)\n",
    "    \n",
    "    return int(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \n",
    "    \"\"\"\n",
    "    Will extract files from all downloaded family .tgz files to a respective directory: ./data/GSE***/\n",
    "    \n",
    "    This will also delete the compressed .tgz files.\n",
    "    \"\"\"\n",
    "    \n",
    "#     find all .tgz files\n",
    "# extract those files\n",
    "# delete the .tgz files\n",
    "\n",
    "    file_list = os.listdir(__base_path)\n",
    "    tgz_list = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match = re.search(r\".tgz\", filename)\n",
    "        if match:\n",
    "            tgz_list.append(filename)\n",
    "                \n",
    "    for filename in tgz_list:\n",
    "        full_path = __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        file = tarfile.open(full_path)\n",
    "        \n",
    "        flag = False\n",
    "        try:\n",
    "            out_path = \"./\" + __base_path + \"/\" + family_id\n",
    "            file.extractall(out_path)\n",
    "        except:\n",
    "#             let's end the content extraction of the file. will fix later.\n",
    "            file.close()\n",
    "    \n",
    "#             out_file = open(out_path)\n",
    "#             out_file.close()\n",
    "            \n",
    "#             os.remove(out_path)\n",
    "            \n",
    "            flag = True\n",
    "            print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "            \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
