{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module that makes downloading and using many GSE datasets fast and easy.\\n\\nAuthor: Joshua Blanchard, last update: 4/28/2021\\n\\nA typical workflow:\\n\\n    Download wanted GSE family files using the download() function.\\n\\n    Extract content from these files using the extract() function.\\n\\n    Use the family_dict() function to convert data to pandas.DataFrame objects.\\n\\n    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"A module that makes downloading and using many GSE datasets fast and easy.\n",
    "\n",
    "Author: Joshua Blanchard, last update: 4/28/2021\n",
    "\n",
    "A typical workflow:\n",
    "\n",
    "    Download wanted GSE family files using the download() function.\n",
    "\n",
    "    Extract content from these files using the extract() function.\n",
    "\n",
    "    Use the family_dict() function to convert data to pandas.DataFrame objects.\n",
    "\n",
    "    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re as re\n",
    "import xmltodict\n",
    "import shutil\n",
    "import ftplib\n",
    "import tarfile\n",
    "import pickle\n",
    "import gzip\n",
    "# import requests\n",
    "# import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__base_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__hidden_path = \".aidp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a family ID, will output a dictionary. Keys will be the sample IDs, values will be the corresponding\n",
    "    pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "\n",
    "#     let's check if we already have this dictionary saved\n",
    "    if not os.path.exists(\"./\" + __hidden_path):\n",
    "        os.mkdir(__hidden_path)\n",
    "    \n",
    "    dict_path = __hidden_path + \"/\" + GSE_family + \"_dict\"    \n",
    "    if not os.path.exists(dict_path):\n",
    "    \n",
    "        family_directory = __family_path(GSE_family)\n",
    "        total_list = os.listdir(family_directory)\n",
    "        valid_files = []\n",
    "\n",
    "        for file_name in total_list:\n",
    "            match = re.match(r\"GSM\", file_name)\n",
    "            if match:\n",
    "                valid_files.append(file_name)\n",
    "\n",
    "        family_dict = {}\n",
    "        for file_name in valid_files:\n",
    "            file_df = __load_file(os.path.join(family_directory, file_name))\n",
    "            sample_id = re.match(r\"GSM\\d+\", file_name).group(0)\n",
    "            family_dict[sample_id] = file_df\n",
    "            \n",
    "        dict_file = open(dict_path, 'wb')\n",
    "        pickle.dump(family_dict, dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "    else:\n",
    "        dict_file = open(dict_path, 'rb')\n",
    "        family_dict = pickle.load(dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "        \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __family_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build paths to the family's directory.\n",
    "    \n",
    "    I downloaded the files using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "        \n",
    "    return os.path.join(__base_path, GSE_family + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_file(file_directory):\n",
    "#     clean data file\n",
    "#     convert to a dataframe object and return\n",
    "\n",
    "    \"\"\"\n",
    "    Given a file name will output a corresponding pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        clean_dict = __clean(file_directory)\n",
    "    except PermissionError:\n",
    "        print(\"You likely inputted the path of a directory, not a file.\")\n",
    "    \n",
    "#     return pd.DataFrame({\"site\": clean_dict[\"col_1\"], \"measurement\": clean_dict[\"col_2\"]})\n",
    "    return pd.DataFrame(data= clean_dict[\"col_2\"], index= clean_dict[\"col_1\"], columns= [\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean(file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans a given .txt file.\n",
    "    \n",
    "    Returns a dictionary:\n",
    "    \n",
    "    \"site\": first column\n",
    "    \"measurement\": second column\n",
    "    \"bad_rows\": list of all the invalid rows\n",
    "    \"\"\"\n",
    "\n",
    "    valid_rows = []\n",
    "    not_valid_rows = []\n",
    "    file = open(file_path, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "#         checks for only the first two columns\n",
    "        line_match = re.match(r\"\\S+\\t\\S+\", line)\n",
    "        if line_match:\n",
    "            valid_rows.append(line_match.group(0))\n",
    "        else:\n",
    "            not_valid_rows.append(line)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "#     now let's split our valid_rows list into two lists, one for each column\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    for row in valid_rows:\n",
    "        row_match = re.match(r\"(\\S+)\\t(\\S+)\", row)\n",
    "        col_1.append(row_match.group(1))\n",
    "        col_2.append(row_match.group(2))\n",
    "        \n",
    "    return {\"col_1\":col_1, \"col_2\":col_2, \"bad_rows\":not_valid_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(GSE_family, sample_id, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": the unit of the outputted age will always be years.\n",
    "    \"\"\"\n",
    "#     create dataframe of sample characteristics portion of the series_matrix file\n",
    "# read desired info from this dataframe. will have to use regex to find the right information\n",
    "# set up some sort of persistance of this dataframe for faster retrieval of information\n",
    "\n",
    "#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\n",
    "\n",
    "    info_df = __matrix_to_df(\"./\" + __base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\", use= \"info()\")\n",
    "    info_series = test_df.loc[:, sample_id]\n",
    "    \n",
    "    for row in info_series:\n",
    "        match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "        if match_age:\n",
    "    #         let's grab the age\n",
    "            match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "            age_float = float(match_age_dig.group())\n",
    "\n",
    "    #         now let's find the unit of age\n",
    "            match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "            match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "            match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "            match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "\n",
    "    #         we always return the age in units of years\n",
    "            if match_years:\n",
    "                return age_float\n",
    "            elif match_months:\n",
    "                return age_float / 12\n",
    "            elif match_days:\n",
    "                return age_float / 365\n",
    "            elif match_hours:\n",
    "                return age_float / 8760\n",
    "            else:\n",
    "    #             if no unit is given we'll default to years\n",
    "                return age_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-fdc366cacd9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GSE17448\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GSM435111\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"age\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-f7f50737f7cf>\u001b[0m in \u001b[0;36minfo\u001b[1;34m(GSE_family, sample_id, info)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0minfo_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__matrix_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m__base_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mGSE_family\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mGSE_family\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_series_matrix.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"info()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0minfo_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-a9d4eb1d4211>\u001b[0m in \u001b[0;36m__matrix_to_df\u001b[1;34m(file_path, use)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstart_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__matrix_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mstart_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series()\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte"
     ]
    }
   ],
   "source": [
    "info(\"GSE17448\", \"GSM435111\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-e9c0af8b1601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m__matrix_to_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/GSE17448/GSE17448_series_matrix.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"info()\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-a9d4eb1d4211>\u001b[0m in \u001b[0;36m__matrix_to_df\u001b[1;34m(file_path, use)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstart_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__matrix_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mstart_row\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muse\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series()\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xb4 in position 271: invalid start byte"
     ]
    }
   ],
   "source": [
    "# __matrix_to_df(\"./data/GSE17448/GSE17448_series_matrix.txt\", use= \"info()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM435111</th>\n",
       "      <th>GSM435112</th>\n",
       "      <th>GSM435113</th>\n",
       "      <th>GSM435116</th>\n",
       "      <th>GSM435117</th>\n",
       "      <th>GSM435118</th>\n",
       "      <th>GSM435119</th>\n",
       "      <th>GSM435120</th>\n",
       "      <th>GSM435127</th>\n",
       "      <th>GSM435128</th>\n",
       "      <th>GSM435129</th>\n",
       "      <th>GSM435130</th>\n",
       "      <th>GSM435131</th>\n",
       "      <th>GSM435132</th>\n",
       "      <th>GSM435133</th>\n",
       "      <th>GSM435134</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!Sample_geo_accession</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!Sample_characteristics_ch1</th>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "      <td>cell type: mesenchymal stromal cells from huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!Sample_characteristics_ch1</th>\n",
       "      <td>age: 50 year old human donor</td>\n",
       "      <td>age: 50 year old human donor</td>\n",
       "      <td>age: 21 year old human donor</td>\n",
       "      <td>age: 25 year old human donor</td>\n",
       "      <td>age: 24 year old human donor</td>\n",
       "      <td>age: 21 year old human donor</td>\n",
       "      <td>age: 25 year old human donor</td>\n",
       "      <td>age: 24 year old human donor</td>\n",
       "      <td>age: 79 year old human donor</td>\n",
       "      <td>age: 79 year old human donor</td>\n",
       "      <td>age: 85 year old human donor</td>\n",
       "      <td>age: 85 year old human donor</td>\n",
       "      <td>age: 53 year old human donor</td>\n",
       "      <td>age: 53 year old human donor</td>\n",
       "      <td>age: 85 year old human donor</td>\n",
       "      <td>age: 85 year old human donor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!Sample_characteristics_ch1</th>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 10</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 11</td>\n",
       "      <td>cell passage: 11</td>\n",
       "      <td>cell passage: 14</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 15</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 10</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 10</td>\n",
       "      <td>cell passage: 2</td>\n",
       "      <td>cell passage: 8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     GSM435111  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 50 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435112  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 50 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 10   \n",
       "\n",
       "                                                                     GSM435113  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 21 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435116  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 25 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435117  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 24 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435118  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 21 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 11   \n",
       "\n",
       "                                                                     GSM435119  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 25 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 11   \n",
       "\n",
       "                                                                     GSM435120  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 24 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 14   \n",
       "\n",
       "                                                                     GSM435127  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 79 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435128  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 79 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 15   \n",
       "\n",
       "                                                                     GSM435129  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 85 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435130  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 85 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 10   \n",
       "\n",
       "                                                                     GSM435131  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 53 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435132  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 53 year old human donor   \n",
       "!Sample_characteristics_ch1                                   cell passage: 10   \n",
       "\n",
       "                                                                     GSM435133  \\\n",
       "!Sample_geo_accession                                                            \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...   \n",
       "!Sample_characteristics_ch1                       age: 85 year old human donor   \n",
       "!Sample_characteristics_ch1                                    cell passage: 2   \n",
       "\n",
       "                                                                     GSM435134  \n",
       "!Sample_geo_accession                                                           \n",
       "!Sample_characteristics_ch1  cell type: mesenchymal stromal cells from huma...  \n",
       "!Sample_characteristics_ch1                       age: 85 year old human donor  \n",
       "!Sample_characteristics_ch1                                    cell passage: 8  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = __matrix_to_df(\"./testing-data/GSE17448_series_matrix.txt\", use= \"info()\")\n",
    "test_df\n",
    "# test_series = test_df.loc[:, \"GSM435111\"]\n",
    "\n",
    "# for row in test_series:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_series:\n",
    "    match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "    if match_age:\n",
    "#         let's grab the age\n",
    "        match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "        age_float = float(match_age_dig.group())\n",
    "        \n",
    "#         now let's find the unit of age\n",
    "        match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "        match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "        match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "        match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "        \n",
    "#         we always return the age in units of years\n",
    "        if match_years:\n",
    "            return age_float\n",
    "        elif match_months:\n",
    "            return age_float / 12\n",
    "        elif match_days:\n",
    "            return age_float / 365\n",
    "        elif match_hours:\n",
    "            return age_float / 8760\n",
    "        else:\n",
    "#             if no unit is given we'll default to years\n",
    "            return age_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"50\") / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series(\"GSE27317\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series(GSE):\n",
    "    \n",
    "    download(GSE, file_type= \"series_matrix\")\n",
    "    extract()\n",
    "    \n",
    "    file_path = os.path.join(__base_path, GSE, GSE + \"_series_matrix.txt\")\n",
    "    \n",
    "    return __matrix_to_df(file_path)\n",
    "    \n",
    "    \n",
    "# download and extract .soft file using the download() and extract() function\n",
    "# convert file to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(__matrix_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_to_df(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns the pandas.dataframe corresponding to the series_matrix file.\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    start_row, num_rows = __matrix_helper(file_path, use)\n",
    "    df = pd.read_csv(file_path, header= start_row, sep= \"\\t\", low_memory= False, nrows= num_rows)\n",
    "    \n",
    "    if use == \"series()\":\n",
    "        df.set_index(\"ID_REF\", inplace= True)\n",
    "    else:\n",
    "        df.set_index(\"!Sample_geo_accession\", inplace= True)\n",
    "        df = df.loc[\"!Sample_characteristics_ch1\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_helper(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns a tuple containing the start line for reading (0) and the number of rows to read (1).\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_path)\n",
    "    \n",
    "    line_num = 0\n",
    "    if use == \"series()\":\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if line == \"!series_matrix_table_begin\\n\":\n",
    "                start_row = line_num\n",
    "            elif line == \"!series_matrix_table_end\\n\":\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if \"!Sample_title\" in line:\n",
    "                start_row = line_num\n",
    "            elif line == \"!series_matrix_table_begin\\n\":\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "\n",
    "    num_rows = end_row - start_row - 1\n",
    "        \n",
    "    return start_row, num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build a path to the family's .xml.\n",
    "    \n",
    "    I downloaded these families using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return os.path.join(__base_path, GSE_family + \"/\" + GSE_family + \"_family.xml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_to_dict(xml_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to convert a .xml file at xml_path to a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_file = open(xml_path,'r+b')\n",
    "    family_dict = xmltodict.parse(family_file)\n",
    "    family_file.close()\n",
    "    \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __dict_index(GSE_family, sample_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gives the index of where in the dictionary the sample's information is.\n",
    "    \"\"\"\n",
    "    \n",
    "    return __sample_indices(GSE_family)[sample_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sample_indices(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to return the indices of each sample's information within the associated family dictionary. Returns a dictionary\n",
    "    with keys equal to the sample ID (\"GSM***\") and values equal to the index of that sample's information within the family\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_dir = __family_path(GSE_family)\n",
    "    file_list = os.listdir(family_dir)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for file_name in file_list:\n",
    "        sample_match = re.match(r\"GSM\", file_name)\n",
    "        if sample_match:\n",
    "            filtered_list.append(file_name)\n",
    "            \n",
    "    for i in np.arange(len(filtered_list)):\n",
    "        filtered_list[i] = re.match(r\"GSM\\d+\", filtered_list[i]).group(0)\n",
    "        \n",
    "    index_dict = {}\n",
    "    index = 0\n",
    "\n",
    "    for sample_id in filtered_list:\n",
    "        index_dict[sample_id] = index\n",
    "        index += 1\n",
    "        \n",
    "    return index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/\" + \"GSE41037\" + \"/miniml/\" + \"GSE41027\" + \"_family.xml.tgz\"\n",
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSE1/miniml/GSE1_family.xml.tgz\"\n",
    "\n",
    "def download(GSE_family_list, file_type= \"miniml\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Will download family .tgz files to the following directory: \"./data/\"\n",
    "    \n",
    "    Possible values for file_type: \"miniml\", \"series_matrix\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(GSE_family_list) == str):\n",
    "        GSE_family_list = [GSE_family_list]\n",
    "\n",
    "    url = \"ftp.ncbi.nlm.nih.gov\"\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login()\n",
    "    \n",
    "    if not os.path.exists(__base_path):\n",
    "        os.mkdir(__base_path)\n",
    "    \n",
    "    for GSE_family in GSE_family_list:\n",
    "        \n",
    "        if file_type == \"miniml\":\n",
    "        \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/miniml/\")\n",
    "            filename = GSE_family + \"_family.xml.tgz\"\n",
    "            \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family)):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/matrix/\")\n",
    "            filename = GSE_family + \"_series_matrix.txt.gz\"\n",
    "        \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\")):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "\n",
    "    ftp.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sub_directory(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE ID will return the corresponding sub-directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    gse_int = __ID_to_int(GSE_ID)\n",
    "    \n",
    "    if gse_int <= 171:\n",
    "        ret_str = \"GSE\" + str(gse_int) + \"nnn\"\n",
    "    else:\n",
    "        first_3_dig = int(str(gse_int)[0:3])\n",
    "        if first_3_dig <= 171:\n",
    "            ret_str = \"GSE\" + str(first_3_dig) + \"nnn\"\n",
    "        else:\n",
    "            first_2_dig_str = str(gse_int)[0:2]\n",
    "            ret_str = \"GSE\" + first_2_dig_str + \"nnn\"\n",
    "            \n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ID_to_int(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given some GSE ID will return the corresponding integer as an int.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    __ID_to_int(\"GSE41037\") will return 41037.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r\"\\d+\", GSE_ID)\n",
    "    \n",
    "    if not match:\n",
    "        print(GSE_ID)\n",
    "    \n",
    "    return int(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \n",
    "    \"\"\"\n",
    "    Will extract files from all downloaded family .tgz files to a respective directory: ./data/GSE***/\n",
    "    \n",
    "    This will also delete the compressed .tgz files.\n",
    "    \"\"\"\n",
    "    \n",
    "#     find all .tgz and .gz files\n",
    "# extract those files\n",
    "# delete the .tgz files\n",
    "\n",
    "    file_list = os.listdir(__base_path)\n",
    "    tgz_list = []\n",
    "    gz_list = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match_tgz = re.search(r\"\\.tgz\", filename)\n",
    "        match_gz = re.search(r\"\\.gz\", filename)\n",
    "        \n",
    "        if match_tgz:\n",
    "            tgz_list.append(filename)\n",
    "        elif match_gz:\n",
    "            gz_list.append(filename)\n",
    "                \n",
    "    for filename in tgz_list:\n",
    "        full_path = __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        file = tarfile.open(full_path)\n",
    "        \n",
    "        flag = False\n",
    "        try:\n",
    "            out_path = \"./\" + __base_path + \"/\" + family_id\n",
    "            file.extractall(out_path)\n",
    "        except:\n",
    "#             let's end the content extraction of the file. will fix later.\n",
    "            file.close()\n",
    "    \n",
    "#             out_file = open(out_path)\n",
    "#             out_file.close()\n",
    "            \n",
    "#             os.remove(out_path)\n",
    "            \n",
    "            flag = True\n",
    "            print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "            \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "            \n",
    "    \n",
    "    for filename in gz_list:\n",
    "        full_path = \"./\" + __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        compressed_file = open(full_path, 'rb')\n",
    "        compressed_file_contents = compressed_file.read()\n",
    "        compressed_file.close()\n",
    "        \n",
    "        contents_bytes = gzip.decompress(compressed_file_contents)\n",
    "        contents_str = contents_bytes.decode()\n",
    "        \n",
    "        family_dir = os.path.join(__base_path, family_id)\n",
    "        if not os.path.exists(family_dir):\n",
    "            os.mkdir(family_dir)\n",
    "        \n",
    "        out_path = \"./\" + __base_path + \"/\" + family_id + \"/\" + family_id + \"_series_matrix.txt\"\n",
    "\n",
    "        file = open(out_path, 'w')\n",
    "        file.write(contents_str)\n",
    "        file.close()\n",
    "        \n",
    "        os.remove(full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
