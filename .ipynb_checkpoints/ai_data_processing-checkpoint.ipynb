{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module that makes downloading and using many GSE datasets fast and easy.\\n\\nAuthor: Joshua Blanchard, last update: 4/28/2021\\n\\nA typical workflow:\\n\\n    Download wanted GSE family files using the download() function.\\n\\n    Extract content from these files using the extract() function.\\n\\n    Use the family_dict() function to convert data to pandas.DataFrame objects.\\n\\n    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"A module that makes downloading and using many GSE datasets fast and easy.\n",
    "\n",
    "Author: Joshua Blanchard, last update: 4/28/2021\n",
    "\n",
    "A typical workflow:\n",
    "\n",
    "    Download wanted GSE family files using the download() function.\n",
    "\n",
    "    Extract content from these files using the extract() function.\n",
    "\n",
    "    Use the family_dict() function to convert data to pandas.DataFrame objects.\n",
    "\n",
    "    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re as re\n",
    "import xmltodict\n",
    "import shutil\n",
    "import ftplib\n",
    "import tarfile\n",
    "import pickle\n",
    "import gzip\n",
    "# import requests\n",
    "# import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__base_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__hidden_path = \".aidp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a family ID, will output a dictionary. Keys will be the sample IDs, values will be the corresponding\n",
    "    pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "\n",
    "#     let's check if we already have this dictionary saved\n",
    "    if not os.path.exists(\"./\" + __hidden_path):\n",
    "        os.mkdir(__hidden_path)\n",
    "    \n",
    "    dict_path = __hidden_path + \"/\" + GSE_family + \"_dict\"    \n",
    "    if not os.path.exists(dict_path):\n",
    "    \n",
    "        family_directory = __family_path(GSE_family)\n",
    "        total_list = os.listdir(family_directory)\n",
    "        valid_files = []\n",
    "\n",
    "        for file_name in total_list:\n",
    "            match = re.match(r\"GSM\", file_name)\n",
    "            if match:\n",
    "                valid_files.append(file_name)\n",
    "\n",
    "        family_dict = {}\n",
    "        for file_name in valid_files:\n",
    "            file_df = __load_file(os.path.join(family_directory, file_name))\n",
    "            sample_id = re.match(r\"GSM\\d+\", file_name).group(0)\n",
    "            family_dict[sample_id] = file_df\n",
    "            \n",
    "        dict_file = open(dict_path, 'wb')\n",
    "        pickle.dump(family_dict, dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "    else:\n",
    "        dict_file = open(dict_path, 'rb')\n",
    "        family_dict = pickle.load(dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "        \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __family_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build paths to the family's directory.\n",
    "    \n",
    "    I downloaded the files using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "        \n",
    "    return os.path.join(__base_path, GSE_family + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_file(file_directory):\n",
    "#     clean data file\n",
    "#     convert to a dataframe object and return\n",
    "\n",
    "    \"\"\"\n",
    "    Given a file name will output a corresponding pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        clean_dict = __clean(file_directory)\n",
    "    except PermissionError:\n",
    "        print(\"You likely inputted the path of a directory, not a file.\")\n",
    "    \n",
    "#     return pd.DataFrame({\"site\": clean_dict[\"col_1\"], \"measurement\": clean_dict[\"col_2\"]})\n",
    "    return pd.DataFrame(data= clean_dict[\"col_2\"], index= clean_dict[\"col_1\"], columns= [\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean(file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans a given .txt file.\n",
    "    \n",
    "    Returns a dictionary:\n",
    "    \n",
    "    \"site\": first column\n",
    "    \"measurement\": second column\n",
    "    \"bad_rows\": list of all the invalid rows\n",
    "    \"\"\"\n",
    "\n",
    "    valid_rows = []\n",
    "    not_valid_rows = []\n",
    "    file = open(file_path, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "#         checks for only the first two columns\n",
    "        line_match = re.match(r\"\\S+\\t\\S+\", line)\n",
    "        if line_match:\n",
    "            valid_rows.append(line_match.group(0))\n",
    "        else:\n",
    "            not_valid_rows.append(line)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "#     now let's split our valid_rows list into two lists, one for each column\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    for row in valid_rows:\n",
    "        row_match = re.match(r\"(\\S+)\\t(\\S+)\", row)\n",
    "        col_1.append(row_match.group(1))\n",
    "        col_2.append(row_match.group(2))\n",
    "        \n",
    "    return {\"col_1\":col_1, \"col_2\":col_2, \"bad_rows\":not_valid_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(GSE_family, sample_id, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": the unit of the outputted age will always be years.\n",
    "    \"\"\"\n",
    "#     create dataframe of sample characteristics portion of the series_matrix file\n",
    "# read desired info from this dataframe. will have to use regex to find the right information\n",
    "# set up some sort of persistance of this dataframe for faster retrieval of information\n",
    "\n",
    "#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\n",
    "\n",
    "    info_df = __matrix_to_df(\"./\" + __base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\", use= \"info()\")    \n",
    "    info_series = info_df.loc[:, sample_id]\n",
    "        \n",
    "    for row in info_series:\n",
    "        match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "        if match_age:\n",
    "    #         let's grab the age\n",
    "            match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "            age_float = float(match_age_dig.group())\n",
    "\n",
    "    #         now let's find the unit of age\n",
    "            match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "            match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "            match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "            match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "\n",
    "    #         we always return the age in units of years\n",
    "            if match_years:\n",
    "                return age_float\n",
    "            elif match_months:\n",
    "                return age_float / 12\n",
    "            elif match_days:\n",
    "                return age_float / 365\n",
    "            elif match_hours:\n",
    "                return age_float / 8760\n",
    "            else:\n",
    "    #             if no unit is given we'll default to years\n",
    "                return age_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data/GSE34257/GSE34257_series_matrix.txt\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u03bc' in position 26206: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-ab72a43241d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# info(\"GSE20236\", \"GSM507152\", \"age\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GSE34257\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_type\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"series_matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# series(\"GSE34257\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-a2be2c2b2245>\u001b[0m in \u001b[0;36mextract\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;31m#         flag = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u03bc' in position 26206: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# info(\"GSE20236\", \"GSM507152\", \"age\")\n",
    "download(\"GSE34257\", file_type= \"series_matrix\")\n",
    "extract()\n",
    "# series(\"GSE34257\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __matrix_to_df(\"./data/GSE17448/GSE17448_series_matrix.txt\", use= \"info()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = __matrix_to_df(\"./data/GSE17448/GSE17448_series_matrix.txt\", use= \"info()\")\n",
    "test_df\n",
    "# test_series = test_df.loc[:, \"GSM435111\"]\n",
    "\n",
    "# for row in test_series:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_series:\n",
    "    match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "    if match_age:\n",
    "#         let's grab the age\n",
    "        match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "        age_float = float(match_age_dig.group())\n",
    "        \n",
    "#         now let's find the unit of age\n",
    "        match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "        match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "        match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "        match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "        \n",
    "#         we always return the age in units of years\n",
    "        if match_years:\n",
    "            return age_float\n",
    "        elif match_months:\n",
    "            return age_float / 12\n",
    "        elif match_days:\n",
    "            return age_float / 365\n",
    "        elif match_hours:\n",
    "            return age_float / 8760\n",
    "        else:\n",
    "#             if no unit is given we'll default to years\n",
    "            return age_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(\"50\") / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series(\"GSE27317\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series(GSE):\n",
    "    \n",
    "    download(GSE, file_type= \"series_matrix\")\n",
    "    extract()\n",
    "    \n",
    "    file_path = os.path.join(__base_path, GSE, GSE + \"_series_matrix.txt\")\n",
    "    \n",
    "    return __matrix_to_df(file_path)\n",
    "    \n",
    "    \n",
    "# download and extract .soft file using the download() and extract() function\n",
    "# convert file to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(__matrix_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_to_df(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns the pandas.dataframe corresponding to the series_matrix file.\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    start_row, num_rows = __matrix_helper(file_path, use)\n",
    "    df = pd.read_csv(file_path, header= start_row, sep= \"\\t\", low_memory= False, nrows= num_rows)\n",
    "    \n",
    "    if use == \"series()\":\n",
    "        df.set_index(\"ID_REF\", inplace= True)\n",
    "    else:\n",
    "        df.set_index(\"!Sample_geo_accession\", inplace= True)\n",
    "        df = df.loc[\"!Sample_characteristics_ch1\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_helper(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns a tuple containing the start line for reading (0) and the number of rows to read (1).\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_path)\n",
    "    \n",
    "    line_num = 0\n",
    "    if use == \"series()\":\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            \n",
    "            if \"!series_matrix_table_begin\" in line:\n",
    "                start_row = line_num\n",
    "            elif \"!series_matrix_table_end\" in line:\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "        \n",
    "    else:\n",
    "                \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if \"!Sample_title\" in line:\n",
    "                start_row = line_num\n",
    "            elif \"!series_matrix_table_begin\" in line:\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "\n",
    "    num_rows = end_row - start_row - 1\n",
    "        \n",
    "    return start_row, num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build a path to the family's .xml.\n",
    "    \n",
    "    I downloaded these families using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return os.path.join(__base_path, GSE_family + \"/\" + GSE_family + \"_family.xml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_to_dict(xml_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to convert a .xml file at xml_path to a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_file = open(xml_path,'r+b')\n",
    "    family_dict = xmltodict.parse(family_file)\n",
    "    family_file.close()\n",
    "    \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __dict_index(GSE_family, sample_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gives the index of where in the dictionary the sample's information is.\n",
    "    \"\"\"\n",
    "    \n",
    "    return __sample_indices(GSE_family)[sample_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sample_indices(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to return the indices of each sample's information within the associated family dictionary. Returns a dictionary\n",
    "    with keys equal to the sample ID (\"GSM***\") and values equal to the index of that sample's information within the family\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_dir = __family_path(GSE_family)\n",
    "    file_list = os.listdir(family_dir)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for file_name in file_list:\n",
    "        sample_match = re.match(r\"GSM\", file_name)\n",
    "        if sample_match:\n",
    "            filtered_list.append(file_name)\n",
    "            \n",
    "    for i in np.arange(len(filtered_list)):\n",
    "        filtered_list[i] = re.match(r\"GSM\\d+\", filtered_list[i]).group(0)\n",
    "        \n",
    "    index_dict = {}\n",
    "    index = 0\n",
    "\n",
    "    for sample_id in filtered_list:\n",
    "        index_dict[sample_id] = index\n",
    "        index += 1\n",
    "        \n",
    "    return index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/\" + \"GSE41037\" + \"/miniml/\" + \"GSE41027\" + \"_family.xml.tgz\"\n",
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSE1/miniml/GSE1_family.xml.tgz\"\n",
    "\n",
    "def download(GSE_family_list, file_type= \"miniml\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Will download family .tgz files to the following directory: \"./data/\"\n",
    "    \n",
    "    Possible values for file_type: \"miniml\", \"series_matrix\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(GSE_family_list) == str):\n",
    "        GSE_family_list = [GSE_family_list]\n",
    "\n",
    "    url = \"ftp.ncbi.nlm.nih.gov\"\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login()\n",
    "    \n",
    "    if not os.path.exists(__base_path):\n",
    "        os.mkdir(__base_path)\n",
    "    \n",
    "    for GSE_family in GSE_family_list:\n",
    "        \n",
    "        if file_type == \"miniml\":\n",
    "        \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/miniml/\")\n",
    "            filename = GSE_family + \"_family.xml.tgz\"\n",
    "            \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family)):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/matrix/\")\n",
    "            filename = GSE_family + \"_series_matrix.txt.gz\"\n",
    "        \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\")):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "\n",
    "    ftp.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sub_directory(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE ID will return the corresponding sub-directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    gse_int = __ID_to_int(GSE_ID)\n",
    "    \n",
    "    if gse_int <= 171:\n",
    "        ret_str = \"GSE\" + str(gse_int) + \"nnn\"\n",
    "    else:\n",
    "        first_3_dig = int(str(gse_int)[0:3])\n",
    "        if first_3_dig <= 171:\n",
    "            ret_str = \"GSE\" + str(first_3_dig) + \"nnn\"\n",
    "        else:\n",
    "            first_2_dig_str = str(gse_int)[0:2]\n",
    "            ret_str = \"GSE\" + first_2_dig_str + \"nnn\"\n",
    "            \n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ID_to_int(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given some GSE ID will return the corresponding integer as an int.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    __ID_to_int(\"GSE41037\") will return 41037.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r\"\\d+\", GSE_ID)\n",
    "    \n",
    "    if not match:\n",
    "        print(GSE_ID)\n",
    "    \n",
    "    return int(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \n",
    "    \"\"\"\n",
    "    Will extract files from all downloaded family .tgz files to a respective directory: ./data/GSE***/\n",
    "    \n",
    "    This will also delete the .tgz and .gz files.\n",
    "    \"\"\"\n",
    "    \n",
    "#     find all .tgz and .gz files\n",
    "# extract those files\n",
    "# delete the .tgz files\n",
    "\n",
    "    file_list = os.listdir(__base_path)\n",
    "    tgz_list = []\n",
    "    gz_list = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match_tgz = re.search(r\"\\.tgz\", filename)\n",
    "        match_gz = re.search(r\"\\.gz\", filename)\n",
    "        \n",
    "        if match_tgz:\n",
    "            tgz_list.append(filename)\n",
    "        elif match_gz:\n",
    "            gz_list.append(filename)\n",
    "                \n",
    "    flag = False\n",
    "    \n",
    "    for filename in tgz_list:\n",
    "        full_path = __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        file = tarfile.open(full_path)\n",
    "        \n",
    "        try:\n",
    "            out_path = \"./\" + __base_path + \"/\" + family_id\n",
    "            file.extractall(out_path)\n",
    "        except:\n",
    "#             let's end the content extraction of the file. will fix later.\n",
    "            file.close()\n",
    "    \n",
    "            flag = True\n",
    "            print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "            \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "            \n",
    "    \n",
    "    for filename in gz_list:\n",
    "        full_path = \"./\" + __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        compressed_file = open(full_path, 'rb')\n",
    "        compressed_file_contents = compressed_file.read()\n",
    "        compressed_file.close()\n",
    "        \n",
    "        contents_bytes = gzip.decompress(compressed_file_contents)\n",
    "        contents_str = contents_bytes.decode(errors= \"ignore\")\n",
    "        \n",
    "        family_dir = os.path.join(__base_path, family_id)\n",
    "        if not os.path.exists(family_dir):\n",
    "            os.mkdir(family_dir)\n",
    "        \n",
    "        out_path = \"./\" + __base_path + \"/\" + family_id + \"/\" + family_id + \"_series_matrix.txt\"\n",
    "\n",
    "        file = open(out_path, 'w')\n",
    "        \n",
    "        file.write(contents_str)\n",
    "#         flag = True\n",
    "        file.close()\n",
    "#         print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "        \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
