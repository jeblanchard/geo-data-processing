{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A module that makes downloading and using many GSE datasets fast and easy.\\n\\nAuthor: Joshua Blanchard, last update: 4/28/2021\\n\\nA typical workflow:\\n\\n    Download wanted GSE family files using the download() function.\\n\\n    Extract content from these files using the extract() function.\\n\\n    Use the family_dict() function to convert data to pandas.DataFrame objects.\\n\\n    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"A module that makes downloading and using many GSE datasets fast and easy.\n",
    "\n",
    "Author: Joshua Blanchard, last update: 4/28/2021\n",
    "\n",
    "A typical workflow:\n",
    "\n",
    "    Download wanted GSE family files using the download() function.\n",
    "\n",
    "    Extract content from these files using the extract() function.\n",
    "\n",
    "    Use the family_dict() function to convert data to pandas.DataFrame objects.\n",
    "\n",
    "    With the info() function, perform data analysis on the previously created pandas.DataFrame objects.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re as re\n",
    "import xmltodict\n",
    "import shutil\n",
    "import ftplib\n",
    "import tarfile\n",
    "import pickle\n",
    "import gzip\n",
    "# import requests\n",
    "# import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__base_path = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__hidden_path = \".aidp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a family ID, will output a dictionary. Keys will be the sample IDs, values will be the corresponding\n",
    "    pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "\n",
    "#     let's check if we already have this dictionary saved\n",
    "    if not os.path.exists(\"./\" + __hidden_path):\n",
    "        os.mkdir(__hidden_path)\n",
    "    \n",
    "    dict_path = __hidden_path + \"/\" + GSE_family + \"_dict\"    \n",
    "    if not os.path.exists(dict_path):\n",
    "    \n",
    "        family_directory = __family_path(GSE_family)\n",
    "        total_list = os.listdir(family_directory)\n",
    "        valid_files = []\n",
    "\n",
    "        for file_name in total_list:\n",
    "            match = re.match(r\"GSM\", file_name)\n",
    "            if match:\n",
    "                valid_files.append(file_name)\n",
    "\n",
    "        family_dict = {}\n",
    "        for file_name in valid_files:\n",
    "            file_df = __load_file(os.path.join(family_directory, file_name))\n",
    "            sample_id = re.match(r\"GSM\\d+\", file_name).group(0)\n",
    "            family_dict[sample_id] = file_df\n",
    "            \n",
    "        dict_file = open(dict_path, 'wb')\n",
    "        pickle.dump(family_dict, dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "    else:\n",
    "        dict_file = open(dict_path, 'rb')\n",
    "        family_dict = pickle.load(dict_file)\n",
    "        dict_file.close()\n",
    "        \n",
    "        \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __family_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build paths to the family's directory.\n",
    "    \n",
    "    I downloaded the files using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "        \n",
    "    return os.path.join(__base_path, GSE_family + \"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __load_file(file_directory):\n",
    "#     clean data file\n",
    "#     convert to a dataframe object and return\n",
    "\n",
    "    \"\"\"\n",
    "    Given a file name will output a corresponding pandas.DataFrame object.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        clean_dict = __clean(file_directory)\n",
    "    except PermissionError:\n",
    "        print(\"You likely inputted the path of a directory, not a file.\")\n",
    "    \n",
    "#     return pd.DataFrame({\"site\": clean_dict[\"col_1\"], \"measurement\": clean_dict[\"col_2\"]})\n",
    "    return pd.DataFrame(data= clean_dict[\"col_2\"], index= clean_dict[\"col_1\"], columns= [\"measurement\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean(file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Cleans a given .txt file.\n",
    "    \n",
    "    Returns a dictionary:\n",
    "    \n",
    "    \"site\": first column\n",
    "    \"measurement\": second column\n",
    "    \"bad_rows\": list of all the invalid rows\n",
    "    \"\"\"\n",
    "\n",
    "    valid_rows = []\n",
    "    not_valid_rows = []\n",
    "    file = open(file_path, 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        \n",
    "#         checks for only the first two columns\n",
    "        line_match = re.match(r\"\\S+\\t\\S+\", line)\n",
    "        if line_match:\n",
    "            valid_rows.append(line_match.group(0))\n",
    "        else:\n",
    "            not_valid_rows.append(line)\n",
    "        \n",
    "    file.close()\n",
    "    \n",
    "#     now let's split our valid_rows list into two lists, one for each column\n",
    "    col_1 = []\n",
    "    col_2 = []\n",
    "    for row in valid_rows:\n",
    "        row_match = re.match(r\"(\\S+)\\t(\\S+)\", row)\n",
    "        col_1.append(row_match.group(1))\n",
    "        col_2.append(row_match.group(2))\n",
    "        \n",
    "    return {\"col_1\":col_1, \"col_2\":col_2, \"bad_rows\":not_valid_rows}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(GSE_family, sample_id, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": the unit of the outputted age will always be years.\n",
    "    \"\"\"\n",
    "#     create dataframe of sample characteristics portion of the series_matrix file\n",
    "# read desired info from this dataframe. will have to use regex to find the right information\n",
    "# set up some sort of persistance of this dataframe for faster retrieval of information\n",
    "\n",
    "#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info(sample_id, info):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE family and the ID of the wanted sample will return the desired information of the sample.\n",
    "    \n",
    "    Possible values for the info parameter:\n",
    "    \n",
    "    \"age\": the unit of the outputted age will always be years.\n",
    "    \"\"\"\n",
    "#     create dataframe of sample characteristics portion of the series_matrix file\n",
    "# read desired info from this dataframe. will have to use regex to find the right information\n",
    "# set up some sort of persistance of this dataframe for faster retrieval of information\n",
    "\n",
    "#             match = re.search(r\"(a|A)(g|G)(e|E)\", tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell type: mesenchymal stromal cells from human bone marrow\n",
      "age: 50 year old human donor\n",
      "cell passage: 2\n"
     ]
    }
   ],
   "source": [
    "test_df = __matrix_to_df(\"./testing-data/GSE17448_series_matrix.txt\", use= \"info()\")\n",
    "test_series = test_df.iloc[:, 0]\n",
    "\n",
    "for row in test_series:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in test_series:\n",
    "    match_age = re.search(r\"(a|A)(g|G)(e|E)\", row)\n",
    "    if match_age:\n",
    "#         let's grab the age\n",
    "        match_age_dig = re.search(r\"\\d+\\.?\\d*\", row)\n",
    "        age_float = float(match_age_dig.group())\n",
    "        \n",
    "#         now let's find the unit of age\n",
    "        match_years = re.search(r\"(y|Y)(e|E)(a|A)(r|R)(s|S)*\", row)\n",
    "        match_months = re.search(r\"(m|M)(o|O)(n|N)(t|T)(h|H)(s|S)*\", row)\n",
    "        match_days = re.search(r\"(d|D)(a|A)(y|Y)(s|S)*\", row)\n",
    "        match_hours = re.search(r\"(h|H)(o|O)(u|U)(r|R)(s|S)*\", row)\n",
    "        \n",
    "#         we always return the age in units of years\n",
    "        if match_years:\n",
    "            return age_float\n",
    "        elif match_months:\n",
    "            return age_float / 12\n",
    "        elif match_days:\n",
    "            return age_float / 365\n",
    "        elif match_hours:\n",
    "            return age_float / 8760\n",
    "        else:\n",
    "#             if no unit is given we'll default to years\n",
    "            return age_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(\"50\") / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSM675231</th>\n",
       "      <th>GSM675232</th>\n",
       "      <th>GSM675233</th>\n",
       "      <th>GSM675234</th>\n",
       "      <th>GSM675235</th>\n",
       "      <th>GSM675236</th>\n",
       "      <th>GSM675237</th>\n",
       "      <th>GSM675238</th>\n",
       "      <th>GSM675239</th>\n",
       "      <th>GSM675240</th>\n",
       "      <th>...</th>\n",
       "      <th>GSM675389</th>\n",
       "      <th>GSM675390</th>\n",
       "      <th>GSM675391</th>\n",
       "      <th>GSM675392</th>\n",
       "      <th>GSM675393</th>\n",
       "      <th>GSM675394</th>\n",
       "      <th>GSM675395</th>\n",
       "      <th>GSM675396</th>\n",
       "      <th>GSM675397</th>\n",
       "      <th>GSM675398</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cg00000292</th>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8630</td>\n",
       "      <td>0.8150</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.9060</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.7930</td>\n",
       "      <td>0.8580</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.8130</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00002426</th>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.7940</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>0.7310</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.8960</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cg00003994</th>\n",
       "      <td>0.0734</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GSM675231  GSM675232  GSM675233  GSM675234  GSM675235  GSM675236  \\\n",
       "ID_REF                                                                         \n",
       "cg00000292     0.8850     0.8630     0.8150      0.872     0.8900     0.8510   \n",
       "cg00002426     0.7900     0.7730     0.6830      0.826     0.7940     0.7400   \n",
       "cg00003994     0.0734     0.0651     0.0577      0.074     0.0805     0.0648   \n",
       "\n",
       "            GSM675237  GSM675238  GSM675239  GSM675240  ...  GSM675389  \\\n",
       "ID_REF                                                  ...              \n",
       "cg00000292     0.9060      0.837     0.8720     0.7700  ...      0.836   \n",
       "cg00002426     0.7310      0.737     0.7380     0.6980  ...      0.905   \n",
       "cg00003994     0.0568      0.119     0.0533     0.0539  ...      0.073   \n",
       "\n",
       "            GSM675390  GSM675391  GSM675392  GSM675393  GSM675394  GSM675395  \\\n",
       "ID_REF                                                                         \n",
       "cg00000292     0.7930     0.8580      0.747     0.7750     0.8130     0.8070   \n",
       "cg00002426     0.8960     0.8980      0.895     0.8650     0.8960     0.9050   \n",
       "cg00003994     0.0497     0.0434      0.032     0.0371     0.0306     0.0245   \n",
       "\n",
       "            GSM675396  GSM675397  GSM675398  \n",
       "ID_REF                                       \n",
       "cg00000292     0.8390     0.8320      0.769  \n",
       "cg00002426     0.9170     0.8940      0.885  \n",
       "cg00003994     0.0291     0.0346      0.032  \n",
       "\n",
       "[3 rows x 168 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series(\"GSE27317\").head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series(GSE):\n",
    "    \n",
    "    download(GSE, file_type= \"series_matrix\")\n",
    "    extract()\n",
    "    \n",
    "    file_path = os.path.join(__base_path, GSE, GSE + \"_series_matrix.txt\")\n",
    "    \n",
    "    return __matrix_to_df(file_path)\n",
    "    \n",
    "    \n",
    "# download and extract .soft file using the download() and extract() function\n",
    "# convert file to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(__matrix_to_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_to_df(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns the pandas.dataframe corresponding to the series_matrix file.\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    start_row, num_rows = __matrix_helper(file_path, use)\n",
    "    df = pd.read_csv(file_path, header= start_row, sep= \"\\t\", low_memory= False, nrows= num_rows)\n",
    "    \n",
    "    if use == \"series()\":\n",
    "        df.set_index(\"ID_REF\", inplace= True)\n",
    "    else:\n",
    "        df.set_index(\"!Sample_geo_accession\", inplace= True)\n",
    "        df = df.loc[\"!Sample_characteristics_ch1\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __matrix_helper(file_path, use= \"series()\"):\n",
    "    \n",
    "    \"\"\"Returns a tuple containing the start line for reading (0) and the number of rows to read (1).\n",
    "    \n",
    "    Possible values for use: \"series()\", \"info()\"\n",
    "    \"\"\"\n",
    "    \n",
    "    file = open(file_path)\n",
    "    \n",
    "    line_num = 0\n",
    "    if use == \"series()\":\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if line == \"!series_matrix_table_begin\\n\":\n",
    "                start_row = line_num\n",
    "            elif line == \"!series_matrix_table_end\\n\":\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        while True:\n",
    "            line = file.readline()\n",
    "\n",
    "            if \"!Sample_title\" in line:\n",
    "                start_row = line_num\n",
    "            elif line == \"!series_matrix_table_begin\\n\":\n",
    "                end_row = line_num - 1\n",
    "            elif line == \"\":\n",
    "                break\n",
    "\n",
    "            line_num += 1\n",
    "\n",
    "    num_rows = end_row - start_row - 1\n",
    "        \n",
    "    return start_row, num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_path(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to build a path to the family's .xml.\n",
    "    \n",
    "    I downloaded these families using the download() function in conjuction with the extract() function.\n",
    "    \"\"\"\n",
    "    \n",
    "    return os.path.join(__base_path, GSE_family + \"/\" + GSE_family + \"_family.xml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __xml_to_dict(xml_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to convert a .xml file at xml_path to a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_file = open(xml_path,'r+b')\n",
    "    family_dict = xmltodict.parse(family_file)\n",
    "    family_file.close()\n",
    "    \n",
    "    return family_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __dict_index(GSE_family, sample_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gives the index of where in the dictionary the sample's information is.\n",
    "    \"\"\"\n",
    "    \n",
    "    return __sample_indices(GSE_family)[sample_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sample_indices(GSE_family):\n",
    "    \n",
    "    \"\"\"\n",
    "    Exists to return the indices of each sample's information within the associated family dictionary. Returns a dictionary\n",
    "    with keys equal to the sample ID (\"GSM***\") and values equal to the index of that sample's information within the family\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    family_dir = __family_path(GSE_family)\n",
    "    file_list = os.listdir(family_dir)\n",
    "    \n",
    "    filtered_list = []\n",
    "    for file_name in file_list:\n",
    "        sample_match = re.match(r\"GSM\", file_name)\n",
    "        if sample_match:\n",
    "            filtered_list.append(file_name)\n",
    "            \n",
    "    for i in np.arange(len(filtered_list)):\n",
    "        filtered_list[i] = re.match(r\"GSM\\d+\", filtered_list[i]).group(0)\n",
    "        \n",
    "    index_dict = {}\n",
    "    index = 0\n",
    "\n",
    "    for sample_id in filtered_list:\n",
    "        index_dict[sample_id] = index\n",
    "        index += 1\n",
    "        \n",
    "    return index_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/\" + \"GSE41037\" + \"/miniml/\" + \"GSE41027\" + \"_family.xml.tgz\"\n",
    "# url = \"ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSEnnn/GSE1/miniml/GSE1_family.xml.tgz\"\n",
    "\n",
    "def download(GSE_family_list, file_type= \"miniml\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Will download family .tgz files to the following directory: \"./data/\"\n",
    "    \n",
    "    Possible values for file_type: \"miniml\", \"series_matrix\"\n",
    "    \"\"\"\n",
    "    \n",
    "    if (type(GSE_family_list) == str):\n",
    "        GSE_family_list = [GSE_family_list]\n",
    "\n",
    "    url = \"ftp.ncbi.nlm.nih.gov\"\n",
    "    ftp = ftplib.FTP(url)\n",
    "    ftp.login()\n",
    "    \n",
    "    if not os.path.exists(__base_path):\n",
    "        os.mkdir(__base_path)\n",
    "    \n",
    "    for GSE_family in GSE_family_list:\n",
    "        \n",
    "        if file_type == \"miniml\":\n",
    "        \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/miniml/\")\n",
    "            filename = GSE_family + \"_family.xml.tgz\"\n",
    "            \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family)):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            ftp.cwd(\"/geo/series/\" + __sub_directory(GSE_family) + \"/\" + GSE_family + \"/matrix/\")\n",
    "            filename = GSE_family + \"_series_matrix.txt.gz\"\n",
    "        \n",
    "            if not (os.path.exists(__base_path + \"/\" + filename) or os.path.exists(__base_path + \"/\" + GSE_family + \"/\" + GSE_family + \"_series_matrix.txt\")):\n",
    "                local_file = open(__base_path + \"/\" + filename, 'wb')\n",
    "                ftp.retrbinary('RETR ' + filename, local_file.write, blocksize= 16_384)\n",
    "                local_file.close()\n",
    "\n",
    "    ftp.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __sub_directory(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a GSE ID will return the corresponding sub-directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    gse_int = __ID_to_int(GSE_ID)\n",
    "    \n",
    "    if gse_int <= 171:\n",
    "        ret_str = \"GSE\" + str(gse_int) + \"nnn\"\n",
    "    else:\n",
    "        first_3_dig = int(str(gse_int)[0:3])\n",
    "        if first_3_dig <= 171:\n",
    "            ret_str = \"GSE\" + str(first_3_dig) + \"nnn\"\n",
    "        else:\n",
    "            first_2_dig_str = str(gse_int)[0:2]\n",
    "            ret_str = \"GSE\" + first_2_dig_str + \"nnn\"\n",
    "            \n",
    "    return ret_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __ID_to_int(GSE_ID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given some GSE ID will return the corresponding integer as an int.\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    __ID_to_int(\"GSE41037\") will return 41037.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r\"\\d+\", GSE_ID)\n",
    "    \n",
    "    if not match:\n",
    "        print(GSE_ID)\n",
    "    \n",
    "    return int(match.group(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    \n",
    "    \"\"\"\n",
    "    Will extract files from all downloaded family .tgz files to a respective directory: ./data/GSE***/\n",
    "    \n",
    "    This will also delete the compressed .tgz files.\n",
    "    \"\"\"\n",
    "    \n",
    "#     find all .tgz and .gz files\n",
    "# extract those files\n",
    "# delete the .tgz files\n",
    "\n",
    "    file_list = os.listdir(__base_path)\n",
    "    tgz_list = []\n",
    "    gz_list = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        match_tgz = re.search(r\"\\.tgz\", filename)\n",
    "        match_gz = re.search(r\"\\.gz\", filename)\n",
    "        \n",
    "        if match_tgz:\n",
    "            tgz_list.append(filename)\n",
    "        elif match_gz:\n",
    "            gz_list.append(filename)\n",
    "                \n",
    "    for filename in tgz_list:\n",
    "        full_path = __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        file = tarfile.open(full_path)\n",
    "        \n",
    "        flag = False\n",
    "        try:\n",
    "            out_path = \"./\" + __base_path + \"/\" + family_id\n",
    "            file.extractall(out_path)\n",
    "        except:\n",
    "#             let's end the content extraction of the file. will fix later.\n",
    "            file.close()\n",
    "    \n",
    "#             out_file = open(out_path)\n",
    "#             out_file.close()\n",
    "            \n",
    "#             os.remove(out_path)\n",
    "            \n",
    "            flag = True\n",
    "            print(\"Something weird happened while extracting from the \" + family_id + \" compressed file. Ended extraction early for \" + family_id + \".\")\n",
    "            \n",
    "        if not flag:\n",
    "            file.close()\n",
    "            os.remove(full_path)\n",
    "            \n",
    "    \n",
    "    for filename in gz_list:\n",
    "        full_path = \"./\" + __base_path + \"/\" + filename\n",
    "        family_id = re.search(r\"GSE\\d+\", filename).group(0)\n",
    "                \n",
    "        compressed_file = open(full_path, 'rb')\n",
    "        compressed_file_contents = compressed_file.read()\n",
    "        compressed_file.close()\n",
    "        \n",
    "        contents_bytes = gzip.decompress(compressed_file_contents)\n",
    "        contents_str = contents_bytes.decode()\n",
    "        \n",
    "        family_dir = os.path.join(__base_path, family_id)\n",
    "        if not os.path.exists(family_dir):\n",
    "            os.mkdir(family_dir)\n",
    "        \n",
    "        out_path = \"./\" + __base_path + \"/\" + family_id + \"/\" + family_id + \"_series_matrix.txt\"\n",
    "\n",
    "        file = open(out_path, 'w')\n",
    "        file.write(contents_str)\n",
    "        file.close()\n",
    "        \n",
    "        os.remove(full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
